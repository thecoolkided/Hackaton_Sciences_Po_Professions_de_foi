{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5d7f6058-d0d1-44af-b43a-cb4b06df03d8",
      "metadata": {
        "id": "5d7f6058-d0d1-44af-b43a-cb4b06df03d8"
      },
      "source": [
        "# Notebook de traitement des professions de foi par catégorisation\n",
        "Ce notebook contient l'ensemble des fonctons que nous avons utilisées sous format prêt à l'emploi pour obtenir les résultats présentés.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "daa37d97-10e4-425d-b852-15bd043662b9",
      "metadata": {
        "id": "daa37d97-10e4-425d-b852-15bd043662b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b5efd35-4e6f-43dc-8a06-1f2d6cdade8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mistralai\n",
            "  Downloading mistralai-1.10.0-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/40.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.2/40.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting eval-type-backport>=0.2.0 (from mistralai)\n",
            "  Downloading eval_type_backport-0.3.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: httpx>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from mistralai) (0.28.1)\n",
            "Collecting invoke<3.0.0,>=2.2.0 (from mistralai)\n",
            "  Downloading invoke-2.2.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.33.1 in /usr/local/lib/python3.12/dist-packages (from mistralai) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.37.0 in /usr/local/lib/python3.12/dist-packages (from mistralai) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.33.1 in /usr/local/lib/python3.12/dist-packages (from mistralai) (1.37.0)\n",
            "Collecting opentelemetry-semantic-conventions<0.60,>=0.59b0 (from mistralai)\n",
            "  Downloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: pydantic>=2.10.3 in /usr/local/lib/python3.12/dist-packages (from mistralai) (2.12.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from mistralai) (2.9.0.post0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=6.0.2 in /usr/local/lib/python3.12/dist-packages (from mistralai) (6.0.3)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from mistralai) (0.4.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->mistralai) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->mistralai) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->mistralai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->mistralai) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.28.1->mistralai) (0.16.0)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api<2.0.0,>=1.33.1->mistralai) (8.7.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api<2.0.0,>=1.33.1->mistralai) (4.15.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.37.0->mistralai) (1.72.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.37.0->mistralai) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.37.0->mistralai) (1.37.0)\n",
            "Requirement already satisfied: requests~=2.7 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.37.0->mistralai) (2.32.4)\n",
            "Requirement already satisfied: protobuf<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-proto==1.37.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.37.0->mistralai) (5.29.5)\n",
            "INFO: pip is looking at multiple versions of opentelemetry-sdk to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.37.0 (from mistralai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.39.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-sdk<2.0.0,>=1.33.1 (from mistralai)\n",
            "  Downloading opentelemetry_sdk-1.39.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-api<2.0.0,>=1.33.1 (from mistralai)\n",
            "  Downloading opentelemetry_api-1.39.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-sdk<2.0.0,>=1.33.1 (from mistralai)\n",
            "  Downloading opentelemetry_sdk-1.39.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-api<2.0.0,>=1.33.1 (from mistralai)\n",
            "  Downloading opentelemetry_api-1.39.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-sdk<2.0.0,>=1.33.1 (from mistralai)\n",
            "  Downloading opentelemetry_sdk-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-api<2.0.0,>=1.33.1 (from mistralai)\n",
            "  Downloading opentelemetry_api-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.39.1 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.37.0->mistralai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.39.1-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.39.1 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.37.0->mistralai)\n",
            "  Downloading opentelemetry_proto-1.39.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.37.0 (from mistralai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.39.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.39.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.37.0->mistralai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.39.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.39.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.37.0->mistralai)\n",
            "  Downloading opentelemetry_proto-1.39.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.37.0 (from mistralai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.38.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.38.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.37.0->mistralai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.38.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.37.0->mistralai)\n",
            "  Downloading opentelemetry_proto-1.38.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.10.3->mistralai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.10.3->mistralai) (2.41.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->mistralai) (1.17.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.33.1->mistralai) (3.23.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests~=2.7->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.37.0->mistralai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests~=2.7->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.37.0->mistralai) (2.5.0)\n",
            "Downloading mistralai-1.10.0-py3-none-any.whl (460 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m461.0/461.0 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading eval_type_backport-0.3.1-py3-none-any.whl (6.1 kB)\n",
            "Downloading invoke-2.2.1-py3-none-any.whl (160 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.3/160.3 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.38.0-py3-none-any.whl (132 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.38.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_http-1.38.0-py3-none-any.whl (19 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.38.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: opentelemetry-proto, invoke, eval-type-backport, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, opentelemetry-semantic-conventions, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-http, mistralai\n",
            "  Attempting uninstall: opentelemetry-proto\n",
            "    Found existing installation: opentelemetry-proto 1.37.0\n",
            "    Uninstalling opentelemetry-proto-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-proto-1.37.0\n",
            "  Attempting uninstall: opentelemetry-exporter-otlp-proto-common\n",
            "    Found existing installation: opentelemetry-exporter-otlp-proto-common 1.37.0\n",
            "    Uninstalling opentelemetry-exporter-otlp-proto-common-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-exporter-otlp-proto-common-1.37.0\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.37.0\n",
            "    Uninstalling opentelemetry-api-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-api-1.37.0\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.58b0\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.58b0:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.58b0\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.37.0\n",
            "    Uninstalling opentelemetry-sdk-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.37.0\n",
            "  Attempting uninstall: opentelemetry-exporter-otlp-proto-http\n",
            "    Found existing installation: opentelemetry-exporter-otlp-proto-http 1.37.0\n",
            "    Uninstalling opentelemetry-exporter-otlp-proto-http-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-exporter-otlp-proto-http-1.37.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-adk 1.21.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.38.0 which is incompatible.\n",
            "google-adk 1.21.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed eval-type-backport-0.3.1 invoke-2.2.1 mistralai-1.10.0 opentelemetry-api-1.38.0 opentelemetry-exporter-otlp-proto-common-1.38.0 opentelemetry-exporter-otlp-proto-http-1.38.0 opentelemetry-proto-1.38.0 opentelemetry-sdk-1.38.0 opentelemetry-semantic-conventions-0.59b0\n"
          ]
        }
      ],
      "source": [
        "! pip install mistralai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae93e75a-fd20-4ca6-9eff-bef7d44ab3a9",
      "metadata": {
        "id": "ae93e75a-fd20-4ca6-9eff-bef7d44ab3a9"
      },
      "outputs": [],
      "source": [
        "from mistralai import Mistral"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99ff9378-c059-4063-a8a0-9ec1d1186954",
      "metadata": {
        "id": "99ff9378-c059-4063-a8a0-9ec1d1186954"
      },
      "outputs": [],
      "source": [
        "api_key = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e030d9c2-1ecb-4bf0-864d-9f96b41bd016",
      "metadata": {
        "id": "e030d9c2-1ecb-4bf0-864d-9f96b41bd016"
      },
      "outputs": [],
      "source": [
        "def run_mistral(user_message, model=\"mistral-large-latest\"):\n",
        "    client = Mistral(api_key=api_key)\n",
        "    messages = [\n",
        "        {\"role\":\"user\", \"content\":user_message}\n",
        "    ]\n",
        "    chat_response = client.chat.complete(\n",
        "        model=model,\n",
        "        messages=messages\n",
        "    )\n",
        "    return (chat_response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b98a29ef-4764-40b7-aed8-0e5d0502f985",
      "metadata": {
        "id": "b98a29ef-4764-40b7-aed8-0e5d0502f985"
      },
      "source": [
        "## Classification\n",
        "Mistral models can easily categorize text into distinct classes. In this example prompt, we can define a list of predefined categories and ask Mistral models to classify user inquiry.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "id": "d71e9d1c-ca45-4d19-882c-07e077ea19ad",
      "metadata": {
        "id": "d71e9d1c-ca45-4d19-882c-07e077ea19ad"
      },
      "outputs": [],
      "source": [
        "def user_message(inquiry):\n",
        "    user_message = (\n",
        "    f\"\"\"\n",
        "            Tu es chercheur en sciences politiques. Ta tâche est d'associer des informations contenues des textes issus de fichiers csv à des catégories prédéfinies. Voici la liste des catégories avec un exemple et une description du contenu qui doit lui être associé sous la forme (catégorie | exemple | description):\n",
        "\n",
        "            #### TRÈS IMPORTANT ####\n",
        "            Tu dois renvoyer les informations sous un format (catégorie1, info11), (catégorie2, info21)... (catégorieN, infoN1)\\n(catégorie1, info21), (catégorie2, info22)... (catégorieN, infoN2)\n",
        "            pour catégorieX une catégorie parmi celles listées ci-dessous et infoXY l'information de la catégorie X pour l'individu Y.\n",
        "            Pense à sauter une ligne entre deux individus.\n",
        "\n",
        "            (dc:identifier | LG17-75-1-VÉRON-12-tour1-profession_foi.pdf | nom du fichier dans Regards citoyens.\n",
        "            Ce nom, qui peut varier selon les années, contient plusieurs infos demandées en métadonnées :\n",
        "            LG = législatives\n",
        "            17 = 2017\n",
        "            75 = code du département\n",
        "            1 = circonscription\n",
        "            VERON = nom du ou de la candidat (e) titulaire\n",
        "            12 = ? numéro séquentiel propre à RC ?\n",
        "            tour1 = tour\n",
        "            Ces informations se trouvent aussi sur le document même, mais n'hésitez pas à utiliser le nom du fichier pour générer automatiquement les métadonnées correspondantes. Ne peut pas être vide),\n",
        "\n",
        "            (ba_nom_titulaire | Véron | la particule, s'il y en a une, est à mettre à la suite du prénom, pas avant le nom. Si tu ne trouves pas de nom, mets \"Pas de candidat individuel\"),\n",
        "\n",
        "            (bb_prenom_titulaire | Pauline | les prénoms composés comportent systématiquement un trait d'union. Si tu ne trouves pas de prénom, mets \"Pas de candidat individuel\"),\n",
        "\n",
        "            (bd_age_titulaire | 43 | soit l'âge, soit l'année de naissance, selon ce qui est indiqué dans le document.),\n",
        "\n",
        "            (be_professionn_titulaire | juriste | attention: on demande la profession actuelle des candidats, pas le métier qu'ils ont pu faire avant.),\n",
        "\n",
        "            (bj_soutien_titulaire | Parti socialiste / Union des démocrates et des écologistes / Génération écologie / Parti radical de gauche | uniquement les partis ou autres organisations : associations, syndicats, etc. qui soutiennent le candidat. Pas ceux qui peuvent être cités à un autre propos, adversaires, par exemple.),\n",
        "\n",
        "            (bk_liste_titulaire | Ensemble une force pour Paris | appellation temporaire à l'occasion de l'élection ex: NUPES, éventuellement un slogan qui identifierait un ensemble de candidats à l'échelle du département ou du pays.),\n",
        "\n",
        "            (ca_nom_suppléant | Eustache | la particule, s'il y en a une, est à mettre à la suite du prénom, pas avant le nom.),\n",
        "\n",
        "            (cb_prenom_suppleant | Guillaume |),\n",
        "\n",
        "            (cd_age_suppleant | |),\n",
        "\n",
        "            (ce_profession_suppleant | cadre dans un label musical | Métier actuel du suppléant),\n",
        "\n",
        "            (cj_soutien_suppleant | Parti socialiste / Union des démocrates et des écologistes / Génération écologie / Parti radical de gauche | Ce sont souvent les mêmes pour le titulaire et le suppléant, mais il peut y avoir des différences, notamment quand titulaire et suppléant appartiennent à deux partis différents alliés pour l'élection),\n",
        "\n",
        "            (ck_liste_suppleant | Ensemble une force pour Paris | Ce sont souvent les mêmes pour le titulaire et le suppléant, mais il peut y avoir des différences, notamment quand titulaire et suppléant appartiennent à deux partis différents alliés pour l'élection),\n",
        "\n",
        "            (dc:title | Élections législatives de 2017, Paris - 75, circonscription n°01 : profession de foi de Pauline Véron au tour 1 | Les données composant le titre apparaissent dans le nom du fichier. Cette donnée peut donc être recomposée par une formule, de sorte de remplir les [] comme suit:\n",
        "            Élections législatives de [année], [nom du département]\n",
        "            - [code INSEE du département], circonscription n°l : profession de foi de [prénom nom du candidat/de la candidate titulaire] au tour [1 ou 2]. Ne peut pas être vide),\n",
        "\n",
        "            (dc:date | 2017-06-11 | il y a deux dates par lot de professions de foi : premier tour et second tour.\n",
        "            les deux dates peuvent apparaître sur le document, il est important de ne retenir dans les métadonnées QUE celle du tour au cours duquel le document est utilisé.\n",
        "            7-06-11 Le format est obligatoirement : AAAA-MM-JJ. Ne peut pas être vide),\n",
        "\n",
        "            (contexte_tour | 1 | seulement 2 valeurs possibles : 1 ou 2. Ne peut pas être vide)\n",
        "\n",
        "            (nom_departement | Paris | parmi\n",
        "            Ain\n",
        "            Aisne\n",
        "            Allier\n",
        "            Alpes-de-Haute-Provence\n",
        "            Hautes-Alpes\n",
        "            Alpes-Maritimes\n",
        "            Ardèche\n",
        "            Ardennes\n",
        "            Ariège\n",
        "            Aube\n",
        "            Aude\n",
        "            Aveyron\n",
        "            Bouches-du-Rhône\n",
        "            Calvados\n",
        "            Cantal\n",
        "            Charente\n",
        "            Charente-Maritime\n",
        "            Cher\n",
        "            Corrèze\n",
        "            Corse\n",
        "            Corse-du-Sud\n",
        "            Haute-Corse\n",
        "            Côte-d'Or\n",
        "            Côtes-d'Armor\n",
        "            Creuse\n",
        "            Dordogne\n",
        "            Doubs\n",
        "            Drôme\n",
        "            Eure\n",
        "            Eure-et-Loir\n",
        "            Finistère\n",
        "            Gard\n",
        "            Haute-Garonne\n",
        "            Gers\n",
        "            Haute-Marne\n",
        "            Mayenne\n",
        "            Meurthe-et-Moselle\n",
        "            Meuse\n",
        "            Morbihan\n",
        "            Moselle\n",
        "            Nièvre\n",
        "            Nord\n",
        "            Oise\n",
        "            OrneR\n",
        "            Pas-de-Calais\n",
        "            Puy-de-Dôme\n",
        "            Pyrénées-Atlantiques\n",
        "            Hautes-Pyrénées\n",
        "            Pyrénées-Orientales\n",
        "            Bas-Rhin\n",
        "            Haut-Rhin\n",
        "            Gironde\n",
        "            Hérault\n",
        "            Ille-et-Vilaine\n",
        "            Indre\n",
        "            Indre-et-Loire\n",
        "            Isère\n",
        "            Jura\n",
        "            Landes\n",
        "            Loir-et-Cher\n",
        "            Loire\n",
        "            Haute-Loire\n",
        "            Loire-Atlantique\n",
        "            Loiret\n",
        "            Lot\n",
        "            Lot-et-Garonne\n",
        "            Lozère\n",
        "            Sarthe\n",
        "            Savoie\n",
        "            Haute-Savoie\n",
        "            Paris\n",
        "            Seine-Maritime\n",
        "            Seine-et-Marne\n",
        "            Yvelines\n",
        "            Deux-Sèvres\n",
        "            Somme\n",
        "            Tarn\n",
        "            Tarn-et-Garonne\n",
        "            Var\n",
        "            Vaucluse\n",
        "            Vendée\n",
        "            Vienne\n",
        "            Haute-Vienne\n",
        "            Vosges\n",
        "            Yonne\n",
        "            Territoire de Belfort\n",
        "            Essonne\n",
        "            Hauts-de-Seine\n",
        "            Seine-St-Denis\n",
        "            Val-de-Marne\n",
        "            Val-d'Oise\n",
        "            Guadeloupe\n",
        "            Martinique\n",
        "            Guyane\n",
        "            La Réunion\n",
        "            Saint-Pierre-et-Miquelon\n",
        "            Mayotte\n",
        "            Wallis-et-Futuna\n",
        "            Polynésie-française\n",
        "            Nouvelle-Calédonie.\n",
        "            – Si tu ne trouves pas, écris : non précisé.\n",
        "            ),\n",
        "\n",
        "            (departement | 75 | parmi 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 2A 2B 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 971 972 973 974 975 976 986 987 988. – Ne peut pas être vide),\n",
        "\n",
        "            (df_circonscription | 1 | de 1 à 55 selon les départements. Ne peut pas être vide)\n",
        "\n",
        "            (bc_sexe_titulaire | F | seulement 3 valeurs possible : H F ou NR)\n",
        "\n",
        "            (bf_mandat_en_cours_titulaire | maire-adjoint | tous les mandats sont à transcrire au masculin. ex : nseillère devient conseiller, adjointe devient adjoint etc.\n",
        "            \"ministre\" est considéré comme un \"mandat\" adjoint\n",
        "            adjoint au maire co-élu régional conseiller communautaire conseiller d'arrondissement conseiller général conseiller général suppléant conseiller municipal conseiller municipal délégué conseiller régional conseiller régional suppléant conseiller suppléant député député européen\n",
        "            élu élu départemental élu du milieu rural élu local élu municipal maire maire-adjoint maire d'arrondissement maire délégué ministre parlementaire européen premier ministre secrétaire d'Etat sénateur),\n",
        "\n",
        "            (bg_mandat_passe_titulaire | adjoint au maire | les mandats assortis de \"sortant\", \"honoraire\", \"ancien\", etc. sont plus facilement repérables en tant que mandats passés)\n",
        "\n",
        "            (bh_associations_titulaire | NR | activité(s) associative(s) mentionnées par le candidat, à simplifier par thématique :\n",
        "            - agriculture\n",
        "            - animaux\n",
        "            - culture\n",
        "            - droits de l'homme\n",
        "            - école\n",
        "            - environnement\n",
        "            - femmes\n",
        "            - groupes de pression\n",
        "            - humanitaire\n",
        "            - local\n",
        "            - non identifié\n",
        "            - non précise\n",
        "            - NR\n",
        "            - politique\n",
        "            - professionnel\n",
        "            - religion\n",
        "            - santé\n",
        "            - socio-caritatif\n",
        "            - sports et loisirs\n",
        "            - syndicat),\n",
        "\n",
        "            (bi_autres_statuts_titulaire | NR | information personnelle considéré comme significative et fournie par le candidat / la candidate concernant :\n",
        "            ARMEE / GUERRE appelé combattant déporté déserteur\n",
        "            objecteur de conscience pompier\n",
        "            prisonnier de guerre rapatrié réfractaire STO réserve résistant\n",
        "            JUSTICE condamné détenu interné\n",
        "            RELIGION catholique chrétien religieux\n",
        "            SANTE\n",
        "            accidenté du travail handicapé interné psychiatrique séropositif\n",
        "            SEXUALITE homosexuel lesbienne trans\n",
        "            TRAVAIL TRAVAIL cessation d'activité contrat emploi solidarité demandeur d'emploi chômeur en conversion en dispense d'activité en formation-rétroconversion étudiant\n",
        "            exclu de la vie économique intérimaire licencié licencié économique pensionné pré-retraité retraité sans emploi stagiaire vacataire\n",
        "            VIE DE FAMILLE célibataire divorcé\n",
        "            femme au foyer mère\n",
        "            mère au foyer mère de famille mère de famille au foyer mère de famille nombreuse père de famille père de famille nombreuse\n",
        "            veuf),\n",
        "\n",
        "            (bl_decorations_titulaire | non | seulement 2 valeurs possibles : oui –une ou plusieurs décorations mentionnées sur le document– ou non –aucune mention. Ne peut pas être vide),\n",
        "\n",
        "            (cc_sexe_suppleant | H | même consigne que pour bc_sexe_titulaire),\n",
        "\n",
        "            (cf_mandat_en_cours_suppleant | NR | même consigne que pour bf_mandat_en_cours_titulaire),\n",
        "\n",
        "            (cg_mandat_passe_suppleant | NR | même consigne que pour bg_mandat_passe_titulaire)\n",
        "\n",
        "            (ch_associations_suppleant | NR | même consigne que pour bh_association_titulaire),\n",
        "\n",
        "            (ci_autres_status_suppleant | NR | même consigne que pour bi_autres_status_titulaire)\n",
        "\n",
        "            (cl_decorations_suppleant | non | même consigne que pour bl_decorations_titulaire. Ne peut pas être vide)\n",
        "\n",
        "            Tu ne répondras qu'avec les catégories prédéfinies. N'inclus pas le mot \"catégorie\". N'ajoute ni explications ni notes.\n",
        "\n",
        "\n",
        "            ####\n",
        "            Voici un exemple :\n",
        "\n",
        "            AVEC LE SOUTIEN DE JEAN-FRÉDÉRIC POISSON\n",
        "            ÉLECTIONS LÉGISLATIVES – 2 e CIRCONSCRIPTION DE PARIS – 11 ET 18 JUIN 2017\n",
        "            Pauline BETTON\n",
        "            ET JEAN DE LÉOTOING , SUPPLÉANT\n",
        "            www.enavant2017.com\n",
        "            l’amour\n",
        "            la France\n",
        "            Pour\n",
        "            de\n",
        "            SERVIR - RÉSISTER - TRANSMETTRE\n",
        "            VOTEZ\n",
        "            MES ENGAGEMENTS\n",
        "            Pour la France\n",
        "            Respecter de la vie humaine de la conception à la mort naturelle.\n",
        "            Protection de la famille, abrogation de la loi « mariage pour tous ».\n",
        "            Rétablir l’universalité des allocations familiales .\n",
        "            Recentrer l’Etat sur ses missions régaliennes (sécurité, investissements stratégiques, défense, justice).\n",
        "            Favoriser la liberté scolaire, relever le ratio privé/public.\n",
        "            Faire de l’apprentissage de l’Histoire et du Français la priorité de l’enseignement .\n",
        "            Libérer les entrepreneurs et les familles du poids de l’administration, encadrer l’ubérisation de l’économie, favoriser la négociation collective.\n",
        "            Pour notre circonscription\n",
        "            Faire vivre notre démocratie et renforcer la confiance : cultiver la proximité avec mes électeurs et les consulter régulièrement en dehors des logiques de partis.\n",
        "            Faire de l’université de la Sorbonne le phare de la formation des élites des pays francophones ravagés par l’émigration .\n",
        "            Appliquer le principe de subsidiarité : confier aux maires la responsabilité de la propreté de leurs arrondissements.\n",
        "            avec Pauline Betton votre député au service du bien commun\n",
        "            Pour la France, j’ai soutenu Jean-Frédéric Poisson aux\n",
        "            Primaires, ensuite j’ai loyalement\n",
        "            soutenu la candidature de François\n",
        "            Fillon à l’élection présidentielle.\n",
        "            Aujourd’hui cependant, je ne puis\n",
        "            me résoudre à abandonner\n",
        "            complètement le gouvernement\n",
        "            du pays au nouveau chef de l’État\n",
        "            pour les cinq prochaines années.\n",
        "            C’est pourquoi, candidate de la famille et\n",
        "            de la filiation, je me présente devant vous à la députation de\n",
        "            la deuxième circonscription  de Paris au siège  de François\n",
        "            Fillon, avec le soutien de Jean Frédéric Poisson.\n",
        "            Je vous propose donc de nous parler pour reconstruire la\n",
        "            droite et de voter pour moi les 11 et 18 juin prochains. En\n",
        "            Avant!\n",
        "            Pauline Betton votre candidate\n",
        "            l’amour\n",
        "            la France\n",
        "            Pour\n",
        "            de\n",
        "            www.pourlamourdelafrance.fr\n",
        "            AVEC LE PCD, REDONNONS FIERTÉ ET DIGNITÉ À LA FRANCE !\n",
        "            Découvrez nos candidats , notre projet et toutes nos propositions sur :\n",
        "            Jean-Frédéric Poisson Président du PCD Député des Yvelines @PourAmourFrance partichretiendemocrate\n",
        "            30 ans, célibataire, diplômée d’EM LYON je vis et travaille à Paris. Expatriée à Moscou en 2013 j’ai défendu la filiation naturelle contre la loi « mariage pour tous » puis j’ai été élue conseiller consulaire en 2014.\n",
        "            Je sais pouvoir compter sur Pauline Betton pour servir, résister, transmettre, et porter nos convictions, sans fléchir, à l’Assemblée nationale. Donnez-nous les moyens de porter votre voix. Pour l’amour de la France !\n",
        "            MON SUPPLÉANT\n",
        "            Jean de LÉOTOING\n",
        "            28 ans, étudiant en Lettres, officier de réserve\n",
        "            vu, le candidat - RCS PARIS B 440 654 069\n",
        "            Powered by TCPDF (www.tcpdf.org)\n",
        "\n",
        "            <<<\n",
        "            Inquiry: {inquiry}\n",
        "            >>>\n",
        "\n",
        "            \"\"\"\n",
        "  )\n",
        "    return user_message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8b208e1",
      "metadata": {
        "id": "f8b208e1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import os\n",
        "# Fonction pour passer la réponse de requête en csv\n",
        "\n",
        "def texte_vers_csv_saut_ligne(texte_brut, nom_fichier_csv):\n",
        "    \"\"\"\n",
        "    Transforme un texte de type:\n",
        "    nom_colonne | valeur\n",
        "    ...\n",
        "    (séparé par un saut de ligne vide entre individus)\n",
        "    en un CSV et l'enregistre localement.\n",
        "    \"\"\"\n",
        "    # Séparer les individus par deux sauts de ligne consécutifs\n",
        "    individus = texte_brut.strip().split('\\n\\n')\n",
        "    colonnes = set()\n",
        "    lignes_dicts = []\n",
        "\n",
        "    for indiv in individus:\n",
        "        if indiv.strip() == \"\":\n",
        "            continue\n",
        "        ligne_dict = {}\n",
        "        for line in indiv.strip().splitlines():\n",
        "            if '|' not in line:\n",
        "                continue\n",
        "            col, val = line.split('|', 1)\n",
        "            ligne_dict[col.strip()] = val.strip()\n",
        "            colonnes.add(col.strip())\n",
        "        lignes_dicts.append(ligne_dict)\n",
        "\n",
        "    colonnes = sorted(list(colonnes))  # tri pour cohérence\n",
        "\n",
        "    # Chemin pour enregistrer le CSV\n",
        "    chemin = os.path.join(os.getcwd(), nom_fichier_csv)\n",
        "\n",
        "    with open(chemin, 'w', newline='', encoding='utf-8') as f:\n",
        "        writer = csv.DictWriter(f, fieldnames=colonnes)\n",
        "        writer.writeheader()\n",
        "        for d in lignes_dicts:\n",
        "            writer.writerow(d)\n",
        "\n",
        "    print(f\"CSV généré et enregistré ici : {chemin}\")"
      ],
      "metadata": {
        "id": "wlcztorX0U53"
      },
      "id": "wlcztorX0U53",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "#### Il faut que mettre sur un google drive les fichiers csv. Ici, ils ont été mis dans le dossier Colab Notebooks\n",
        "# qui est créé automatiquement par la commande drive.mount.\n",
        "# Dans ce cas, le chemin est celui dans la variable folder en dessous"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-AFXUsSheI9",
        "outputId": "5c5db1a1-d1d3-422c-9f13-13c674926361"
      },
      "id": "v-AFXUsSheI9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "# Cellule de load des fichiers (sous forme de dataframes) dans la liste batches\n",
        "# Quand lancée, elle doit print \"Loaded batch_test_x.csv with 11 rows\" 50 fois et après \"50 dataframes in total\" s'il y a 50 fichiers de 11 lignes.\n",
        "# C'est normal si les fichiers traités ne le sont pas dans l'ordre.\n",
        "\n",
        "folder = Path(\"/content/drive/MyDrive/Colab Notebooks/batches_mistral_test/\")\n",
        "endFolder = \"/content/drive/MyDrive/Colab Notebooks/rawFiles/\"\n",
        "\n",
        "batches = []\n",
        "\n",
        "for f in folder.iterdir():\n",
        "    if f.is_file() and f.suffix == \".csv\":  # S'assurer que le fichier a une extension \".csv\"\n",
        "        try:\n",
        "            df = pd.read_csv(f)\n",
        "            print(f\"Loaded {f.name} with {len(df)} rows\")\n",
        "            batches.append(df)\n",
        "        except Exception as e:\n",
        "            print(f\"Skipping {f.name}: {e}\")\n",
        "\n",
        "print(f\"{len(batches)} dataframes loaded in total\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qS6SPZ-YZ-ZP",
        "outputId": "bd820472-74c5-4878-8d95-d1ad4bd655e4"
      },
      "id": "qS6SPZ-YZ-ZP",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded batch_test_15.csv with 11 rows\n",
            "Loaded batch_test_7.csv with 11 rows\n",
            "Loaded batch_test_0.csv with 11 rows\n",
            "Loaded batch_test_4.csv with 11 rows\n",
            "Loaded batch_test_47.csv with 11 rows\n",
            "Loaded batch_test_5.csv with 11 rows\n",
            "Loaded batch_test_38.csv with 11 rows\n",
            "Loaded batch_test_2.csv with 11 rows\n",
            "Loaded batch_test_27.csv with 11 rows\n",
            "Loaded batch_test_39.csv with 11 rows\n",
            "Loaded batch_test_36.csv with 11 rows\n",
            "Loaded batch_test_25.csv with 11 rows\n",
            "Loaded batch_test_48.csv with 11 rows\n",
            "Loaded batch_test_30.csv with 11 rows\n",
            "Loaded batch_test_21.csv with 11 rows\n",
            "Loaded batch_test_24.csv with 11 rows\n",
            "Loaded batch_test_19.csv with 11 rows\n",
            "Loaded batch_test_16.csv with 11 rows\n",
            "Loaded batch_test_31.csv with 11 rows\n",
            "Loaded batch_test_9.csv with 11 rows\n",
            "Loaded batch_test_29.csv with 11 rows\n",
            "Loaded batch_test_23.csv with 11 rows\n",
            "Loaded batch_test_18.csv with 11 rows\n",
            "Loaded batch_test_1.csv with 11 rows\n",
            "Loaded batch_test_20.csv with 11 rows\n",
            "Loaded batch_test_22.csv with 11 rows\n",
            "Loaded batch_test_17.csv with 11 rows\n",
            "Loaded batch_test_26.csv with 11 rows\n",
            "Loaded batch_test_43.csv with 11 rows\n",
            "Loaded batch_test_32.csv with 11 rows\n",
            "Loaded batch_test_46.csv with 11 rows\n",
            "Loaded batch_test_33.csv with 11 rows\n",
            "Loaded batch_test_28.csv with 11 rows\n",
            "Loaded batch_test_41.csv with 11 rows\n",
            "Loaded batch_test_42.csv with 11 rows\n",
            "Loaded batch_test_35.csv with 11 rows\n",
            "Loaded batch_test_37.csv with 11 rows\n",
            "Loaded batch_test_6.csv with 11 rows\n",
            "Loaded batch_test_14.csv with 11 rows\n",
            "Loaded batch_test_49.csv with 11 rows\n",
            "Loaded batch_test_11.csv with 11 rows\n",
            "Loaded batch_test_8.csv with 11 rows\n",
            "Loaded batch_test_34.csv with 11 rows\n",
            "Loaded batch_test_3.csv with 11 rows\n",
            "Loaded batch_test_45.csv with 11 rows\n",
            "Loaded batch_test_10.csv with 11 rows\n",
            "Loaded batch_test_44.csv with 11 rows\n",
            "Loaded batch_test_40.csv with 11 rows\n",
            "Loaded batch_test_12.csv with 11 rows\n",
            "Loaded batch_test_13.csv with 11 rows\n",
            "50 dataframes loaded in total\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test pour vérifier la forme de ce qui est dans le premier élément batch\n",
        "\"\"\"\n",
        "for i, batch in enumerate(batches):\n",
        "      if (i==0):\n",
        "        # merge text columns\n",
        "        batch[\"merged_text\"] = batch.iloc[:, 1:].apply(lambda row: \" \".join(row.dropna().astype(str)), axis=1)\n",
        "\n",
        "\n",
        "        # convert each row to dict\n",
        "        lignes = batch.to_dict(orient=\"records\")\n",
        "        print(batch)\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "HFBUZ0glyEnc",
        "outputId": "7403dc4d-8463-4794-c121-3d9361c2062b"
      },
      "id": "HFBUZ0glyEnc",
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfor i, batch in enumerate(batches):\\n      if (i==0):\\n        # merge text columns\\n        batch[\"merged_text\"] = batch.iloc[:, 1:].apply(lambda row: \" \".join(row.dropna().astype(str)), axis=1)\\n\\n\\n        # convert each row to dict\\n        lignes = batch.to_dict(orient=\"records\")\\n        print(batch)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Autre fonction pour transcrire les textes envoyés par les LLMs en CSV.\n",
        "def convert_text_to_csv(input_text, output_file):\n",
        "    \"\"\"\n",
        "    Convert text format to CSV where each individual is separated by blank lines\n",
        "    and each line has format: column_name, value\n",
        "\n",
        "    Args:\n",
        "        input_text: String with the data\n",
        "        output_file: Path to output CSV file\n",
        "    \"\"\"\n",
        "    # Split by blank lines to get individual records\n",
        "    blocks = input_text.strip().split('\\n\\n')\n",
        "\n",
        "    all_records = []\n",
        "\n",
        "    for block in blocks:\n",
        "        if not block.strip():\n",
        "            continue\n",
        "\n",
        "        lines = block.strip().split('\\n')\n",
        "        record = {}\n",
        "\n",
        "        # First line is the filename (identifier)\n",
        "        if lines:\n",
        "            # Skip the first line if it's just the filename without comma\n",
        "            start_idx = 1 if ',' not in lines[0] else 0\n",
        "\n",
        "            for line in lines[start_idx:]:\n",
        "                # Split by first comma only\n",
        "                if ',' in line:\n",
        "                    parts = line.split(',', 1)\n",
        "                    if len(parts) == 2:\n",
        "                        column = parts[0].strip()\n",
        "                        value = parts[1].strip()\n",
        "                        record[column] = value\n",
        "\n",
        "        if record:\n",
        "            all_records.append(record)\n",
        "\n",
        "    if not all_records:\n",
        "        print(\"No records found\")\n",
        "        return\n",
        "\n",
        "    # Get all unique column names (preserve order)\n",
        "    all_columns = []\n",
        "    seen = set()\n",
        "    for record in all_records:\n",
        "        for col in record.keys():\n",
        "            if col not in seen:\n",
        "                all_columns.append(col)\n",
        "                seen.add(col)\n",
        "\n",
        "    # Write to CSV\n",
        "    with open(output_file, 'w', newline='', encoding='utf-8') as f:\n",
        "        writer = csv.DictWriter(f, fieldnames=all_columns)\n",
        "        writer.writeheader()\n",
        "        writer.writerows(all_records)\n",
        "\n",
        "    print(f\"✓ Written {len(all_records)} records to {output_file}\")\n",
        "    print(f\"✓ Columns: {len(all_columns)}\")\n",
        "    return all_records\n"
      ],
      "metadata": {
        "id": "86At41QeaVAs"
      },
      "id": "86At41QeaVAs",
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##################################### THE CELLULE #####################################\n",
        "# Elle se run sur les batches (sous-fichiers de 11 individus) construit précédemment à partir du dossier issu du Google Drive connecté.\n",
        "# Je pense que c'est mieux est de créer dossier \"results\" dans le dossier Colab Notebooks de façon à trier proprement, parce qu'il enregistre\n",
        "# les résultats dedans.\n",
        "answers_2 = []\n",
        "\n",
        "for i, _batch in enumerate(batches):\n",
        "  if (i == 0): # Ne lance que sur le premier fichier, pour tester que cela fonctionne.\n",
        "        # merge text columns\n",
        "        _batch[\"merged_text\"] = _batch.iloc[:, 1:].apply(lambda row: \" \".join(row.dropna().astype(str)), axis=1)\n",
        "        batch = _batch[[\"filename\", \"merged_text\"]]\n",
        "\n",
        "        # convert each row to dict\n",
        "        lignes = batch.to_dict(orient=\"records\")\n",
        "\n",
        "        # call your function on the list of dicts (like before)\n",
        "        var = run_mistral(user_message(lignes), model=\"ministral-14b-2512\")#magistral-small-2509\n",
        "\n",
        "        # save result\n",
        "        with open(endFolder + f\"resultatsBatch{i}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(var)\n",
        "\n",
        "        answers_2.append(var)\n",
        "\n",
        "        # Enregistre dans le fichier results sous le nom \"resultsBatch_i.csv\" pour i le numéro du batch.\n",
        "        texte_vers_csv_saut_ligne(var, \"/content/drive/MyDrive/Colab Notebooks/results/resultsBatch_\"+str(i)+\".csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vfW8FUGsAJ0",
        "outputId": "9c063563-d6fd-43b2-ae01-9798e077a9c1"
      },
      "id": "-vfW8FUGsAJ0",
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV généré et enregistré ici : /content/drive/MyDrive/Colab Notebooks/results/resultsMinistral/resultsBatch_0.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#[texte_vers_csv_saut_ligne(answers[i], \"/content/drive/MyDrive/Colab Notebooks/results/resultsBatch_\"+str(i)+\".csv\") for i in range(54)]"
      ],
      "metadata": {
        "id": "bArLMwEoarkp"
      },
      "id": "bArLMwEoarkp",
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### Pour mettre les informations de chaque batch dans un DataFrame propre (sans lignes vides), puis dans un fichier csv\n",
        "for i in range(10):\n",
        "    path = f\"/content/drive/MyDrive/Colab Notebooks/results/resultsBatch_{i}.csv\"\n",
        "    try:\n",
        "        df = pd.read_csv(path)\n",
        "        df = df.dropna(how=\"all\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Missing file: {path}\")\n",
        "\n",
        "    df.to_csv(\"/content/drive/MyDrive/Colab Notebooks/cleanedBatches0-9/resultsClean\"+str(i)+\".csv\")\n",
        "    print(len(df), \"rows total\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tR8firzo_hqF",
        "outputId": "2db76839-0b95-4c52-daef-80725bb2e3ef"
      },
      "id": "tR8firzo_hqF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11 rows total\n",
            "11 rows total\n",
            "11 rows total\n",
            "11 rows total\n",
            "11 rows total\n",
            "11 rows total\n",
            "11 rows total\n",
            "11 rows total\n",
            "11 rows total\n",
            "11 rows total\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### Pour mettre les informations de tous les batch dans un unique DataFrame, puis dans un unique fichier csv\n",
        "dfs = []\n",
        "\n",
        "for i in range(50):\n",
        "    path = f\"/content/drive/MyDrive/Colab Notebooks/results/resultsBatch_{i}.csv\"\n",
        "    try:\n",
        "        df = pd.read_csv(path)\n",
        "        df = df.dropna(how=\"all\")\n",
        "        dfs.append(df)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Missing file: {path}\")\n",
        "\n",
        "final_df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "print(len(final_df), \"rows total\")\n",
        "\n",
        "final_df.to_csv(\"/content/drive/MyDrive/Colab Notebooks/results/resultsAll.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8TaBl_4jbXE",
        "outputId": "37e58b2b-6cc1-45b4-9e18-b91ca38d5a79"
      },
      "id": "z8TaBl_4jbXE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "550 rows total\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(var)\n",
        "#with open(\"\")\n",
        "variableMini = var"
      ],
      "metadata": {
        "id": "4qQiDvsYoEtF"
      },
      "id": "4qQiDvsYoEtF",
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YYcVN79ovF66"
      },
      "id": "YYcVN79ovF66",
      "execution_count": 137,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "jupytext": {
      "formats": "ipynb,py:light"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}