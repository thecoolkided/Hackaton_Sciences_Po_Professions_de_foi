{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd0cdf94-f4df-4fdb-98a3-25cf9ce12d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import argparse\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b6026472-05bb-4fd9-ab71-31ce3e0385be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Normalisation des fichiers CSV : aligner les colonnes sur le GOLD\n",
    "# - Prend tous les fichiers CSV du dossier RESULTS_DIR\n",
    "# - Crée de nouveaux CSV dans OUT_DIR, où :\n",
    "#     * les colonnes suivent EXACTEMENT le même ordre que dans le GOLD\n",
    "#     * les colonnes manquantes sont ajoutées (NaN)\n",
    "#     * les colonnes en trop sont supprimées\n",
    "# - Le nom du fichier est conservé\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "RESULTS_DIR = \"/Users/quentinnippert/Documents/hackaton_week/SciencePo_project/evaluation_résultats_LLM/resultats_LLM\"\n",
    "GOLD_CSV = \"/Users/quentinnippert/Documents/hackaton_week/SciencePo_project/evaluation_résultats_LLM/Gold.csv\"\n",
    "PATTERN = \"*.csv\"\n",
    "\n",
    "OUT_DIR = \"/Users/quentinnippert/Documents/hackaton_week/SciencePo_project/evaluation_résultats_LLM/resultats_LLM/normalized_outputs\"   # сюда сохраняем новые файлы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e899e01-a8f2-41f8-9ca5-b455b81ec226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready, fichiers sauvegardés ici: /Users/quentinnippert/Documents/hackaton_week/SciencePo_project/evaluation_résultats_LLM/resultats_LLM/normalized_outputs\n",
      "Nombre des fichiers: 3\n",
      "Nombre des coulonnes(gold): 32\n"
     ]
    }
   ],
   "source": [
    "def read_csv_any(path: str) -> pd.DataFrame:\n",
    "    \"\"\"Чтение CSV: сначала ',' потом ';'.\"\"\"\n",
    "    try:\n",
    "        return pd.read_csv(path)\n",
    "    except Exception:\n",
    "        return pd.read_csv(path, sep=\";\")\n",
    "\n",
    "# 1) Читаем gold и берём порядок колонок\n",
    "gold_df = read_csv_any(GOLD_CSV)\n",
    "gold_cols = list(gold_df.columns)\n",
    "\n",
    "# 2) Собираем файлы моделей\n",
    "files = sorted(glob.glob(os.path.join(RESULTS_DIR, PATTERN)))\n",
    "files = [f for f in files if os.path.abspath(f) != os.path.abspath(GOLD_CSV)]\n",
    "\n",
    "if not files:\n",
    "    raise RuntimeError(f\"Нет файлов в {RESULTS_DIR} по паттерну {PATTERN}\")\n",
    "\n",
    "# 3) Создаём папку для результатов\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# 4) Приводим каждый файл к колонкам gold и сохраняем\n",
    "for f in files:\n",
    "    df = read_csv_any(f)\n",
    "\n",
    "    # Добавляем недостающие колонки\n",
    "    for c in gold_cols:\n",
    "        if c not in df.columns:\n",
    "            df[c] = pd.NA\n",
    "\n",
    "    # Удаляем лишние колонки + ставим порядок как в gold\n",
    "    df_norm = df[gold_cols]\n",
    "\n",
    "    out_path = os.path.join(OUT_DIR, os.path.basename(f))\n",
    "    df_norm.to_csv(out_path, index=False)\n",
    "\n",
    "print(f\"Ready, fichiers sauvegardés ici: {OUT_DIR}\")\n",
    "print(f\"Nombre des fichiers: {len(files)}\")\n",
    "print(f\"Nombre des coulonnes(gold): {len(gold_cols)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be70c5c6-28bc-4a9b-8f28-3bb94bcc1292",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "52ee8a39-01ee-415f-b19e-6484d5b3b3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Paramètres à modifier\n",
    "# ----------------------------\n",
    "\n",
    "# Dossier qui contient les CSV produits par les modèles (un fichier = un modèle)\n",
    "RESULTS_DIR = \"/Users/quentinnippert/Documents/hackaton_week/SciencePo_project/evaluation_résultats_LLM/resultats_LLM/normalized_outputs\" \n",
    "\n",
    "# Fichier CSV annoté (gold) avec les bons résultats\n",
    "GOLD_CSV = \"/Users/quentinnippert/Documents/hackaton_week/SciencePo_project/evaluation_résultats_LLM/Gold.csv\"\n",
    "\n",
    "# (Optionnel) motif pour filtrer les fichiers\n",
    "PATTERN = \"*.csv\"\n",
    "\n",
    "# (Optionnel) si vos lignes doivent être alignées via une colonne id (sinon on compare par index 0..n-1)\n",
    "ID_COL = None   # ex: \"id\"  ou laissez None\n",
    "\n",
    "# Seuil de similarité (Jaccard) sur les \"mots essentiels\" (0..1)\n",
    "JACCARD_THRESHOLD = 0.80\n",
    "\n",
    "# Nom du fichier de sortie\n",
    "OUT_SUMMARY_CSV = \"/Users/quentinnippert/Documents/hackaton_week/SciencePo_project/evaluation_résultats_LLM/summary.csv\"\n",
    "\n",
    "EXPORT_PER_MODEL_PER_COLUMN = True\n",
    "OUT_PER_COLUMN_DIR = \"/Users/quentinnippert/Documents/hackaton_week/SciencePo_project/evaluation_résultats_LLM/per_model_columns\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "92dd9af4-edec-4c8b-a929-25558d221daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = {\n",
    "    # FR articles/determiners/pronouns/common function words\n",
    "    \"le\",\"la\",\"les\",\"un\",\"une\",\"des\",\"du\",\"de\",\"d\",\"de\",\"au\",\"aux\",\n",
    "    \"ce\",\"cet\",\"cette\",\"ces\",\"mon\",\"ma\",\"mes\",\"ton\",\"ta\",\"tes\",\"son\",\"sa\",\"ses\",\n",
    "    \"notre\",\"nos\",\"votre\",\"vos\",\"leur\",\"leurs\",\n",
    "    \"et\",\"ou\",\"mais\",\"donc\",\"or\",\"ni\",\"car\",\n",
    "    \"a\",\"à\",\"en\",\"dans\",\"sur\",\"sous\",\"chez\",\"par\",\"pour\",\"avec\",\"sans\",\"vers\",\"entre\",\n",
    "    \"que\",\"qui\",\"quoi\",\"dont\",\"où\",\n",
    "    \"ne\",\"pas\",\"plus\",\"moins\",\"très\",\n",
    "    # EN tiny set (на случай смешанных ответов)\n",
    "    \"the\",\"a\",\"an\",\"and\",\"or\",\"of\",\"to\",\"in\",\"on\",\"for\",\"with\",\"without\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c4362bfc-2316-4b5d-a91f-aeaa2c34be3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Lecture CSV + préparation index\n",
    "# ----------------------------\n",
    "\n",
    "def read_csv_any(path: str) -> pd.DataFrame:\n",
    "    \"\"\"Lecture CSV robuste: essaie ',' puis ';'.\"\"\"\n",
    "    try:\n",
    "        return pd.read_csv(path)\n",
    "    except Exception:\n",
    "        return pd.read_csv(path, sep=\";\")\n",
    "\n",
    "\n",
    "def prepare_df(df: pd.DataFrame, id_col: Optional[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Prépare un DataFrame:\n",
    "    - si id_col est défini : utiliser cette colonne comme index.\n",
    "    \"\"\"\n",
    "    if id_col is not None:\n",
    "        if id_col not in df.columns:\n",
    "            raise ValueError(f\"Colonne ID '{id_col}' introuvable dans le CSV.\")\n",
    "        df = df.set_index(id_col)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "876fe87f-6cd7-476c-b5a3-dfa2676d4db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Détection NR / manquant\n",
    "# ----------------------------\n",
    "\n",
    "def is_missing_or_nr(x) -> bool:\n",
    "    \"\"\"\n",
    "    True si la cellule correspond à une absence d'information :\n",
    "    - None\n",
    "    - NaN (pandas)\n",
    "    - chaîne vide\n",
    "    - 'NR'\n",
    "    - 'non précisé'\n",
    "    \"\"\"\n",
    "    if x is None:\n",
    "        return True\n",
    "\n",
    "    if isinstance(x, float) and pd.isna(x):\n",
    "        return True\n",
    "\n",
    "    if isinstance(x, str):\n",
    "        s = x.strip().lower()\n",
    "        return s in {\n",
    "            \"\",\n",
    "            \"nr\",\n",
    "            \"nan\",\n",
    "            \"non précisé\",\n",
    "            \"non precise\",   # au cas où sans accent\n",
    "        }\n",
    "\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "150efd54-25ed-4605-ac13-66b0bed3e228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Normalisation \"info vs info\"\n",
    "# ----------------------------\n",
    "\n",
    "def normalize_info_text(x) -> str:\n",
    "    \"\"\"\n",
    "    Normalisation appliquée UNIQUEMENT aux cellules informatives (non NR).\n",
    "    - \"/\" -> \"et\"\n",
    "    - minuscules\n",
    "    - suppression ponctuation\n",
    "    - espaces normalisés\n",
    "    \"\"\"\n",
    "    s = str(x).strip().lower()\n",
    "    s = re.sub(r\"\\s*/\\s*\", \" et \", s)\n",
    "    s = re.sub(r\"[^\\w\\s]\", \" \", s, flags=re.UNICODE)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "\n",
    "def content_words(s: str) -> List[str]:\n",
    "    \"\"\"Tokens 'essentiels' : sans stopwords, tokens > 1 char.\"\"\"\n",
    "    if not s:\n",
    "        return []\n",
    "    toks = s.split()\n",
    "    return [t for t in toks if t not in STOPWORDS and len(t) > 1]\n",
    "\n",
    "\n",
    "def jaccard(a: List[str], b: List[str]) -> float:\n",
    "    sa, sb = set(a), set(b)\n",
    "    if not sa and not sb:\n",
    "        return 1.0\n",
    "    if not sa or not sb:\n",
    "        return 0.0\n",
    "    return len(sa & sb) / len(sa | sb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d72b47b8-527f-4180-a169-f5357d72cb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Règle finale de comparaison d'une cellule\n",
    "# ----------------------------\n",
    "\n",
    "def cell_equal(pred, gold, jaccard_threshold: float = JACCARD_THRESHOLD) -> bool:\n",
    "    \"\"\"\n",
    "    1) gold NR/NaN/vide + pred NR/NaN/vide => True\n",
    "    2) gold NR/NaN/vide + pred info        => False\n",
    "    3) gold info        + pred NR/NaN/vide => False\n",
    "    4) gold info        + pred info        => comparaison robuste (Jaccard)\n",
    "    \"\"\"\n",
    "    gold_missing = is_missing_or_nr(gold)\n",
    "    pred_missing = is_missing_or_nr(pred)\n",
    "\n",
    "    if gold_missing and pred_missing:\n",
    "        return True\n",
    "    if gold_missing != pred_missing:\n",
    "        return False\n",
    "\n",
    "    # обе стороны информативные\n",
    "    g = normalize_info_text(gold)\n",
    "    p = normalize_info_text(pred)\n",
    "\n",
    "    if p == g:\n",
    "        return True\n",
    "\n",
    "    gw = content_words(g)\n",
    "    pw = content_words(p)\n",
    "\n",
    "    if not gw and not pw:\n",
    "        return p == g\n",
    "\n",
    "    return jaccard(pw, gw) >= jaccard_threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d6d515c5-1bc2-4dbb-be63-90f81061149c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Règle finale de comparaison d'une cellule\n",
    "# ----------------------------\n",
    "\n",
    "def cell_equal(pred, gold, jaccard_threshold: float = JACCARD_THRESHOLD) -> bool:\n",
    "    \"\"\"\n",
    "    1) gold NR/NaN/vide + pred NR/NaN/vide => True\n",
    "    2) gold NR/NaN/vide + pred info        => False\n",
    "    3) gold info        + pred NR/NaN/vide => False\n",
    "    4) gold info        + pred info        => comparaison robuste (Jaccard)\n",
    "    \"\"\"\n",
    "    gold_missing = is_missing_or_nr(gold)\n",
    "    pred_missing = is_missing_or_nr(pred)\n",
    "\n",
    "    if gold_missing and pred_missing:\n",
    "        return True\n",
    "    if gold_missing != pred_missing:\n",
    "        return False\n",
    "\n",
    "    # обе стороны информативные\n",
    "    g = normalize_info_text(gold)\n",
    "    p = normalize_info_text(pred)\n",
    "\n",
    "    if p == g:\n",
    "        return True\n",
    "\n",
    "    gw = content_words(g)\n",
    "    pw = content_words(p)\n",
    "\n",
    "    if not gw and not pw:\n",
    "        return p == g\n",
    "\n",
    "    return jaccard(pw, gw) >= jaccard_threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "07a2a336-5f39-443b-97b1-b9764ac9a0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Alignement des tables (colonnes + index)\n",
    "# ----------------------------\n",
    "\n",
    "def align_tables(pred: pd.DataFrame, gold: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Aligne pred sur gold:\n",
    "    - ajoute colonnes manquantes (NaN)\n",
    "    - garde uniquement colonnes du gold et dans le même ordre\n",
    "    - aligne lignes via l'index du gold\n",
    "    \"\"\"\n",
    "    pred = pred.copy()\n",
    "    gold = gold.copy()\n",
    "\n",
    "    for col in gold.columns:\n",
    "        if col not in pred.columns:\n",
    "            pred[col] = pd.NA\n",
    "\n",
    "    pred = pred[gold.columns]\n",
    "    pred = pred.reindex(gold.index)\n",
    "\n",
    "    return pred, gold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "45d14f6b-abe1-4e84-8aff-ac7ecb684eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Résultats + métriques\n",
    "# ----------------------------\n",
    "\n",
    "@dataclass\n",
    "class CompareResult:\n",
    "    model_name: str\n",
    "    cell_accuracy: float\n",
    "    macro_col_accuracy: float\n",
    "    per_col_accuracy: Dict[str, float]\n",
    "    n_cells: int\n",
    "\n",
    "\n",
    "def compare_df(pred: pd.DataFrame, gold: pd.DataFrame, model_name: str) -> CompareResult:\n",
    "    \"\"\"\n",
    "    Calcule :\n",
    "    - cell_accuracy : accuracy sur toutes les cellules\n",
    "    - macro_col_accuracy : moyenne des accuracies par colonne\n",
    "    \"\"\"\n",
    "    pred, gold = align_tables(pred, gold)\n",
    "\n",
    "    per_col_accuracy: Dict[str, float] = {}\n",
    "    total_correct = 0\n",
    "    total_cells = 0\n",
    "\n",
    "    cols = list(gold.columns)\n",
    "    n_rows = len(gold)\n",
    "\n",
    "    for j, col in enumerate(cols):\n",
    "        correct_col = 0\n",
    "\n",
    "        for i in range(n_rows):\n",
    "            total_cells += 1\n",
    "            if cell_equal(pred.iat[i, j], gold.iat[i, j]):\n",
    "                correct_col += 1\n",
    "                total_correct += 1\n",
    "\n",
    "        per_col_accuracy[col] = correct_col / n_rows if n_rows else 0.0\n",
    "\n",
    "    cell_accuracy = total_correct / total_cells if total_cells else 0.0\n",
    "    macro_col_accuracy = sum(per_col_accuracy.values()) / len(per_col_accuracy) if per_col_accuracy else 0.0\n",
    "\n",
    "    return CompareResult(\n",
    "        model_name=model_name,\n",
    "        cell_accuracy=cell_accuracy,\n",
    "        macro_col_accuracy=macro_col_accuracy,\n",
    "        per_col_accuracy=per_col_accuracy,\n",
    "        n_cells=total_cells\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e2e211ee-9e4f-4a00-aabb-64014ffadbf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>cell_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mistral_Large_3</td>\n",
       "      <td>0.974432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ChatBot_ChatGPT</td>\n",
       "      <td>0.400568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MiniMistral</td>\n",
       "      <td>0.323864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model  cell_accuracy\n",
       "0  Mistral_Large_3       0.974432\n",
       "1  ChatBot_ChatGPT       0.400568\n",
       "2      MiniMistral       0.323864"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Exécution : comparer tous les CSV du dossier\n",
    "# ----------------------------\n",
    "\n",
    "gold = read_csv_any(GOLD_CSV)\n",
    "gold = prepare_df(gold, ID_COL)\n",
    "\n",
    "files = sorted(glob.glob(os.path.join(RESULTS_DIR, PATTERN)))\n",
    "files = [f for f in files if os.path.abspath(f) != os.path.abspath(GOLD_CSV)]\n",
    "\n",
    "if not files:\n",
    "    raise RuntimeError(f\"Aucun fichier trouvé dans {RESULTS_DIR} avec le motif {PATTERN}\")\n",
    "\n",
    "# Créer dossier pour exports par colonne (optionnel)\n",
    "if EXPORT_PER_MODEL_PER_COLUMN:\n",
    "    os.makedirs(OUT_PER_COLUMN_DIR, exist_ok=True)\n",
    "\n",
    "results: List[CompareResult] = []\n",
    "\n",
    "for f in files:\n",
    "    model_name = os.path.splitext(os.path.basename(f))[0]  # имя файла без расширения\n",
    "    pred = read_csv_any(f)\n",
    "    pred = prepare_df(pred, ID_COL)\n",
    "\n",
    "    res = compare_df(pred, gold, model_name=model_name)\n",
    "    results.append(res)\n",
    "\n",
    "    # Export optionnel : accuracy par colonne pour ce modèle\n",
    "    if EXPORT_PER_MODEL_PER_COLUMN:\n",
    "        per_col_df = (\n",
    "            pd.DataFrame({\"column\": list(res.per_col_accuracy.keys()),\n",
    "                          \"accuracy\": list(res.per_col_accuracy.values())})\n",
    "            .sort_values(\"accuracy\", ascending=False)\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "        per_col_df.to_csv(os.path.join(OUT_PER_COLUMN_DIR, f\"per_column_{model_name}.csv\"), index=False)\n",
    "\n",
    "# Table récapitulative LLM\n",
    "summary = (\n",
    "    pd.DataFrame([{\n",
    "        \"model\": r.model_name,\n",
    "        \"cell_accuracy\": r.cell_accuracy,\n",
    "        #\"macro_accuracy\": r.macro_col_accuracy,\n",
    "        #\"n_cells\": r.n_cells\n",
    "    } for r in results])\n",
    "    .sort_values([\"cell_accuracy\"\n",
    "                  #, \"macro_accuracy\"\n",
    "                 ], ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "40c73dcf-0547-4284-a874-2abc879b31b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/quentinnippert/Documents/hackaton_week/SciencePo_project/evaluation_résultats_LLM/summary.csv\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Sauvegarde du récapitulatif\n",
    "# ----------------------------\n",
    "\n",
    "summary.to_csv(OUT_SUMMARY_CSV, index=False)\n",
    "print(\"Saved:\", OUT_SUMMARY_CSV)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef7502d-63d4-4edd-83f2-a2d129a9ed6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio311",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
